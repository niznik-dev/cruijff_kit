#!/bin/bash
#SBATCH --job-name=<JOBNAME> # Job name
#SBATCH --nodes=1 # Number of nodes
#SBATCH --ntasks=1 # Number of tasks
#SBATCH --cpus-per-task=1
#SBATCH --mem=8G # Memory allocation
#SBATCH --time=00:15:00 # Time limit (HH:MM:SS)
#SBATCH --mail-type=begin # Email when job starts
#SBATCH --mail-type=end # Email when job ends
#SBATCH --mail-user=<NETID>@princeton.edu
#SBATCH --gres=gpu:1 # Request 1 GPU
##SBATCH --array=0-<ARRAY_MAX> # Uncomment if using job arrays
##SBATCH --account=<ACT>
##SBATCH --partition=<PART>
##SBATCH --constraint=<CONST>

module purge
module load anaconda3/2025.6
conda activate <CONDA_ENV>

mkdir -p <OUTPUT_DIR>logs/wandb  # wandb is picky about existing dirs
cp finetune.slurm setup_finetune.yaml <OUTPUT_DIR>/  # Copy config to output dir for reference
tune run lora_finetune_single_device \
    --config finetune.yaml
# Move SLURM log to output dir if successful (only if not already there)
[ $? == 0 ] && [ ! -f <OUTPUT_DIR>/slurm-${SLURM_JOB_ID}.out ] && mv slurm-${SLURM_JOB_ID}.out <OUTPUT_DIR>/