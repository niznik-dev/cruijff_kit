# Refactoring Plan: design-experiment Skill

**Status:** Planning
**Created:** 2025-11-25
**Goal:** Replace `experiment_summary.md` with structured `experiment_summary.yaml` and machine-readable `.jsonl` logs

## Table of Contents

1. [Motivation](#motivation)
2. [Current State](#current-state)
3. [Desired State](#desired-state)
4. [YAML Schema Specification](#yaml-schema-specification)
5. [Log Format Specification](#log-format-specification)
6. [File-by-File Changes](#file-by-file-changes)
7. [Implementation Order](#implementation-order)
8. [Testing Strategy](#testing-strategy)
9. [Migration Notes](#migration-notes)

---

## Motivation

### Problems with Current Approach

1. **Markdown is unstructured**: Parsing requires brittle text pattern matching
2. **Duplicate information**: Quick Reference section repeats information from other sections
3. **Mixed concerns**: Human-readable narrative mixed with machine-readable configuration
4. **Bloat**: Compute Estimates and Quick Reference aren't used by downstream skills
5. **Inconsistent across sessions**: Free-form text makes it hard to replicate experiment designs

### Benefits of YAML Approach

1. **Structured and parseable**: Native YAML parsing is robust and well-supported
2. **Machine-readable**: Easy for downstream skills to consume
3. **De-duplicated**: Each piece of information appears once in its logical location
4. **Consistent**: Schema enforces structure across sessions and experiments
5. **Separation of concerns**: Configuration in YAML, audit trail in logs
6. **Replicable**: Structured format makes it easy to create similar experiments

---

## Current State

### Files Generated by design-experiment

- `{experiment_dir}/experiment_summary.md` - 10-section Markdown document
- `{experiment_dir}/design-experiment.log` - Human-readable text log

### What Downstream Skills Parse

**scaffold-torchtune** parses from `experiment_summary.md`:
- Experiment name (title, line 1)
- Experiment directory (Quick Reference → Paths)
- All Runs table (run names, parameters, Type column)
- Model path (Resources → Models)
- Dataset path, label, format, splits (Resources → Dataset)
- Configuration: epochs, GPUs, batch size, LoRA parameters, system prompt, validation

**scaffold-inspect** parses from `experiment_summary.md`:
- Experiment name (title)
- Experiment directory (Quick Reference → Paths)
- All Runs table (to identify control/base runs)
- Model paths (Resources → Models)
- Evaluation Tasks table (task name, script path, dataset, description)
- Evaluation Plan (which epochs, which runs × tasks)
- System prompt (Configuration section)
- Output directory base (Configuration → Output)

**Not used by downstream skills:**
- Overview section (except name, type, date)
- Tools section (read only by scaffold-experiment orchestrator)
- Variables section (human-readable only)
- Compute Estimates section (not parsed)
- Quick Reference section (not parsed)
- Naming Conventions section (not parsed)

---

## Desired State

### Files Generated by design-experiment

- `{experiment_dir}/experiment_summary.yaml` - Structured configuration
- `{experiment_dir}/design-experiment.jsonl` - Machine-readable audit log

### Verification Strategy

- Skill verifies resources (models, datasets, eval tasks) **during creation**
- Verification results logged to `.jsonl` file
- No "verified" timestamps stored in YAML (reduces clutter)
- If verification fails, skill reports error and doesn't create YAML

---

## YAML Schema Specification

### Complete Schema

```yaml
# experiment_summary.yaml

experiment:
  name: string                    # REQUIRED: Experiment identifier
  type: string                    # REQUIRED: "sanity_check" or "experiment"
  question: string                # REQUIRED: Scientific question being addressed
  date: string                    # REQUIRED: YYYY-MM-DD format
  hypothesis: string              # OPTIONAL: Expected outcome
  purpose: string                 # OPTIONAL: Why this experiment matters
  directory: string               # REQUIRED: Full path to experiment directory

tools:
  preparation: string             # REQUIRED: "torchtune" (for scaffold routing)
  evaluation: string              # REQUIRED: "inspect-ai" (for scaffold routing)

variables:
  # OPTIONAL: Parameters that vary across runs
  # Key = parameter name, Value = list of values to sweep
  lora_rank: [int, int, ...]
  learning_rate: [float, float, ...]
  batch_size: [int, int, ...]
  # ... any parameter that varies

controls:
  # REQUIRED: Parameters held constant across all runs
  base_recipe: string             # Torchtune recipe name
  epochs: int                     # Number of training epochs
  batch_size: int                 # If not varied
  system_prompt: string           # Training system prompt ("" for blank)
  validation_during_training: bool
  gpus: int
  lora_alpha: int                 # If not varied
  # ... any other constant parameters

models:
  base:
    - name: string                # REQUIRED: Model identifier
      path: string                # REQUIRED: Full path to model directory
      size_gb: float              # REQUIRED: Model size for disk estimates

data:
  training:
    path: string                  # REQUIRED: Full path to training dataset
    label: string                 # REQUIRED: Filename without extension
    format: string                # REQUIRED: "json" or "parquet"
    size_kb: int                  # REQUIRED: Dataset size
    splits:                       # REQUIRED: Sample counts per split
      train: int
      validation: int
      test: int

output:
  base_directory: string          # REQUIRED: Where checkpoints are saved
  checkpoint_pattern: string      # REQUIRED: Pattern for checkpoint paths
  wandb_project: string           # REQUIRED: Weights & Biases project name

runs:
  # REQUIRED: List of all runs (fine-tuned + control)
  # Generated from cartesian product of variables + explicit controls
  - name: string                  # REQUIRED: Run identifier (used for directory name)
    type: string                  # REQUIRED: "fine-tuned" or "control"
    model: string                 # REQUIRED: Model name (matches models.base[].name)
    parameters:                   # REQUIRED: Parameter values for this run
      lora_rank: int              # Include all varied parameters
      learning_rate: float
      # Empty dict {} for control runs

evaluation:
  system_prompt: string           # REQUIRED: Must match training system prompt
  temperature: float              # REQUIRED: Evaluation temperature
  scorer: string                  # REQUIRED: Inspect-ai scorer type

  tasks:
    # REQUIRED: List of evaluation tasks
    - name: string                # REQUIRED: Task identifier
      script: string              # REQUIRED: Full path to inspect-ai task script
      dataset: string             # OPTIONAL: Path to eval dataset (if different from training)
      description: string         # REQUIRED: Human-readable task description

  matrix:
    # REQUIRED: Which runs evaluate on which tasks at which epochs
    - run: string                 # REQUIRED: Run name (matches runs[].name)
      tasks: [string, ...]        # REQUIRED: List of task names
      epochs: [int, ...]          # REQUIRED: List of epoch numbers (0-indexed)
                                  # Use null for control runs (no epochs)
```

### Example: Simple LoRA Rank Comparison

```yaml
experiment:
  name: "cap_4L_lora_rank_comparison"
  type: "sanity_check"
  question: "Does LoRA rank affect capitalization performance?"
  date: "2025-10-22"
  directory: "/scratch/gpfs/MSALGANIK/niznik/cap_4L_lora_rank_comparison"

tools:
  preparation: "torchtune"
  evaluation: "inspect-ai"

variables:
  lora_rank: [4, 8]

controls:
  base_recipe: "lora_finetune_single_device"
  epochs: 1
  batch_size: 4
  system_prompt: ""
  validation_during_training: true
  gpus: 1
  lora_alpha: 16

models:
  base:
    - name: "Llama-3.2-1B-Instruct"
      path: "/scratch/gpfs/MSALGANIK/niznik/llms/Meta-Llama-3.2-1B-Instruct"
      size_gb: 4.0

data:
  training:
    path: "/home/sarahep/cruijff_kit/data/green/words_5L_80P_1000.json"
    label: "words_5L_80P_1000"
    format: "json"
    size_kb: 84
    splits:
      train: 1000
      validation: 200
      test: 200

output:
  base_directory: "/scratch/gpfs/MSALGANIK/niznik"
  checkpoint_pattern: "ck-out-{run_name}/epoch_{N}"
  wandb_project: "capitalization"

runs:
  - name: "Llama-3.2-1B-Instruct_rank4"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 4

  - name: "Llama-3.2-1B-Instruct_rank8"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 8

  - name: "Llama-3.2-1B-Instruct_base"
    type: "control"
    model: "Llama-3.2-1B-Instruct"
    parameters: {}

evaluation:
  system_prompt: ""
  temperature: 0.0
  scorer: "match"

  tasks:
    - name: "capitalization"
      script: "/home/sarahep/cruijff_kit/experiments/capitalization/cap_task.py"
      description: "Tests model ability to capitalize words"

  matrix:
    - run: "Llama-3.2-1B-Instruct_rank4"
      tasks: ["capitalization"]
      epochs: [0]

    - run: "Llama-3.2-1B-Instruct_rank8"
      tasks: ["capitalization"]
      epochs: [0]

    - run: "Llama-3.2-1B-Instruct_base"
      tasks: ["capitalization"]
      epochs: null
```

### Example: Complex Multi-Variable Sweep

```yaml
experiment:
  name: "cap_4L_lora_lr_sweep"
  type: "experiment"
  question: "How do LoRA rank and learning rate interact to affect performance?"
  date: "2025-10-24"
  hypothesis: "Higher ranks need lower learning rates for optimal performance"
  purpose: "Identify optimal hyperparameter combinations for production"
  directory: "/scratch/gpfs/MSALGANIK/niznik/cap_4L_lora_lr_sweep"

tools:
  preparation: "torchtune"
  evaluation: "inspect-ai"

variables:
  lora_rank: [8, 16, 32, 64]
  learning_rate: [1e-5, 5e-5]

controls:
  base_recipe: "lora_finetune_single_device"
  epochs: 3
  batch_size: 4
  system_prompt: "You are a helpful assistant."
  validation_during_training: true
  gpus: 1
  lora_alpha: 16

models:
  base:
    - name: "Llama-3.2-1B-Instruct"
      path: "/scratch/gpfs/MSALGANIK/niznik/llms/Meta-Llama-3.2-1B-Instruct"
      size_gb: 4.0

data:
  training:
    path: "/home/sarahep/cruijff_kit/data/green/words_4L_80P_300.json"
    label: "words_4L_80P_300"
    format: "json"
    size_kb: 24
    splits:
      train: 300
      validation: 100
      test: 100

output:
  base_directory: "/scratch/gpfs/MSALGANIK/niznik"
  checkpoint_pattern: "ck-out-{run_name}/epoch_{N}"
  wandb_project: "capitalization"

runs:
  # Cartesian product: 4 ranks × 2 learning rates = 8 fine-tuned runs
  - name: "rank8_lr1e-5"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 8
      learning_rate: 1e-5

  - name: "rank8_lr5e-5"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 8
      learning_rate: 5e-5

  - name: "rank16_lr1e-5"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 16
      learning_rate: 1e-5

  - name: "rank16_lr5e-5"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 16
      learning_rate: 5e-5

  - name: "rank32_lr1e-5"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 32
      learning_rate: 1e-5

  - name: "rank32_lr5e-5"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 32
      learning_rate: 5e-5

  - name: "rank64_lr1e-5"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 64
      learning_rate: 1e-5

  - name: "rank64_lr5e-5"
    type: "fine-tuned"
    model: "Llama-3.2-1B-Instruct"
    parameters:
      lora_rank: 64
      learning_rate: 5e-5

evaluation:
  system_prompt: "You are a helpful assistant."
  temperature: 0.0
  scorer: "match"

  tasks:
    - name: "capitalization"
      script: "/home/sarahep/cruijff_kit/experiments/capitalization/cap_task.py"
      description: "Tests model ability to capitalize words"
    - name: "memorization"
      script: "/home/sarahep/cruijff_kit/experiments/memorization/mem_task.py"
      description: "Tests whether model memorized training data"

  matrix:
    # All fine-tuned runs evaluated on both tasks at epochs 0 and 2
    - run: "rank8_lr1e-5"
      tasks: ["capitalization", "memorization"]
      epochs: [0, 2]

    - run: "rank8_lr5e-5"
      tasks: ["capitalization", "memorization"]
      epochs: [0, 2]

    - run: "rank16_lr1e-5"
      tasks: ["capitalization", "memorization"]
      epochs: [0, 2]

    - run: "rank16_lr5e-5"
      tasks: ["capitalization", "memorization"]
      epochs: [0, 2]

    - run: "rank32_lr1e-5"
      tasks: ["capitalization", "memorization"]
      epochs: [0, 2]

    - run: "rank32_lr5e-5"
      tasks: ["capitalization", "memorization"]
      epochs: [0, 2]

    - run: "rank64_lr1e-5"
      tasks: ["capitalization", "memorization"]
      epochs: [0, 2]

    - run: "rank64_lr5e-5"
      tasks: ["capitalization", "memorization"]
      epochs: [0, 2]
```

---

## Log Format Specification

### File Format: `.jsonl` (JSON Lines)

Each line is a complete JSON object representing one log entry. This format is:
- **Machine-readable**: Easy to parse with standard JSON libraries
- **Streamable**: Can be written incrementally during skill execution
- **Queryable**: Easy to filter/analyze with tools like `jq`, `grep`, or pandas

### Log Entry Schema

```json
{
  "timestamp": "ISO8601 string",      // REQUIRED: When action occurred
  "action": "ACTION_TYPE",            // REQUIRED: What happened (see Action Types)
  "result": "success|failure|warning", // REQUIRED: Outcome
  "duration_ms": 123,                 // OPTIONAL: How long action took
  "...": "..."                        // ACTION-SPECIFIC: Additional fields
}
```

### Action Types

#### START_DESIGN
```json
{
  "timestamp": "2025-10-22T14:30:00.000Z",
  "action": "START_DESIGN",
  "result": "success",
  "experiment_name": "cap_4L_lora_rank_comparison",
  "experiment_type": "sanity_check",
  "experiment_dir": "/scratch/gpfs/MSALGANIK/niznik/cap_4L_lora_rank_comparison"
}
```

#### VERIFY_MODEL
```json
{
  "timestamp": "2025-10-22T14:30:01.123Z",
  "action": "VERIFY_MODEL",
  "result": "success",
  "resource_type": "model",
  "resource_name": "Llama-3.2-1B-Instruct",
  "path": "/scratch/gpfs/MSALGANIK/niznik/llms/Meta-Llama-3.2-1B-Instruct",
  "command": "ls -lh /scratch/gpfs/MSALGANIK/niznik/llms/Meta-Llama-3.2-1B-Instruct",
  "size_gb": 4.0,
  "duration_ms": 45
}
```

#### VERIFY_DATASET
```json
{
  "timestamp": "2025-10-22T14:30:01.456Z",
  "action": "VERIFY_DATASET",
  "result": "success",
  "resource_type": "dataset",
  "path": "/home/sarahep/cruijff_kit/data/green/words_5L_80P_1000.json",
  "command": "ls -lh /home/sarahep/cruijff_kit/data/green/words_5L_80P_1000.json",
  "size_kb": 84,
  "duration_ms": 23
}
```

#### COUNT_DATASET_SAMPLES
```json
{
  "timestamp": "2025-10-22T14:30:01.789Z",
  "action": "COUNT_DATASET_SAMPLES",
  "result": "success",
  "dataset": "words_5L_80P_1000.json",
  "command": "jq '.train | length' /home/sarahep/cruijff_kit/data/green/words_5L_80P_1000.json",
  "train_samples": 1000,
  "validation_samples": 200,
  "test_samples": 200,
  "duration_ms": 156
}
```

#### VERIFY_EVAL_TASK
```json
{
  "timestamp": "2025-10-22T14:30:02.012Z",
  "action": "VERIFY_EVAL_TASK",
  "result": "success",
  "task_name": "capitalization",
  "script_path": "/home/sarahep/cruijff_kit/experiments/capitalization/cap_task.py",
  "command": "ls -lh /home/sarahep/cruijff_kit/experiments/capitalization/cap_task.py",
  "size_kb": 12,
  "duration_ms": 34
}
```

#### SEARCH_PRIOR_RUNS
```json
{
  "timestamp": "2025-10-22T14:30:02.234Z",
  "action": "SEARCH_PRIOR_RUNS",
  "result": "success",
  "search_pattern": "find /scratch/gpfs/MSALGANIK/niznik -name 'slurm-*.out' -path '*/ck-out-*'",
  "command": "find /scratch/gpfs/MSALGANIK/niznik -name 'slurm-*.out' -path '*/ck-out-*' | head -10",
  "found_count": 3,
  "paths": [
    "/scratch/gpfs/MSALGANIK/niznik/prior_exp/run1/slurm-123.out",
    "/scratch/gpfs/MSALGANIK/niznik/prior_exp/run2/slurm-456.out"
  ],
  "duration_ms": 890
}
```

#### EXTRACT_TRAINING_SPEED
```json
{
  "timestamp": "2025-10-22T14:30:03.567Z",
  "action": "EXTRACT_TRAINING_SPEED",
  "result": "success",
  "prior_run": "/scratch/gpfs/MSALGANIK/niznik/prior_exp/run1/slurm-123.out",
  "command": "grep -E '[0-9.]+it/s' /scratch/.../slurm-123.out | tail -20",
  "iterations_per_sec": 2.5,
  "estimated_seconds_per_epoch": 120,
  "duration_ms": 234
}
```

#### CALCULATE_TRAINING_TIME
```json
{
  "timestamp": "2025-10-22T14:30:04.890Z",
  "action": "CALCULATE_TRAINING_TIME",
  "result": "success",
  "basis": "prior_run_average",
  "per_epoch_seconds": 120,
  "epochs": 1,
  "num_runs": 2,
  "total_seconds": 240,
  "total_minutes": 4
}
```

#### CHECK_DISK_SPACE
```json
{
  "timestamp": "2025-10-22T14:30:05.123Z",
  "action": "CHECK_DISK_SPACE",
  "result": "success",
  "command": "df -h /scratch/gpfs/MSALGANIK/niznik",
  "available_gb": 5120,
  "used_gb": 2048,
  "total_gb": 7168,
  "duration_ms": 67
}
```

#### CALCULATE_DISK_USAGE
```json
{
  "timestamp": "2025-10-22T14:30:05.456Z",
  "action": "CALCULATE_DISK_USAGE",
  "result": "success",
  "per_checkpoint_gb": 2.5,
  "epochs": 1,
  "num_runs": 2,
  "total_checkpoints": 2,
  "total_gb": 5.0
}
```

#### GENERATE_RUNS
```json
{
  "timestamp": "2025-10-22T14:30:06.789Z",
  "action": "GENERATE_RUNS",
  "result": "success",
  "method": "cartesian_product",
  "variables": {
    "lora_rank": [4, 8]
  },
  "generated_count": 2,
  "control_runs": 1,
  "total_runs": 3
}
```

#### GENERATE_EVAL_MATRIX
```json
{
  "timestamp": "2025-10-22T14:30:07.012Z",
  "action": "GENERATE_EVAL_MATRIX",
  "result": "success",
  "num_runs": 3,
  "num_tasks": 1,
  "total_evaluations": 3
}
```

#### CREATE_YAML
```json
{
  "timestamp": "2025-10-22T14:30:08.234Z",
  "action": "CREATE_YAML",
  "result": "success",
  "file_path": "/scratch/gpfs/MSALGANIK/niznik/cap_4L_lora_rank_comparison/experiment_summary.yaml",
  "size_bytes": 1456
}
```

#### CREATE_LOG
```json
{
  "timestamp": "2025-10-22T14:30:08.567Z",
  "action": "CREATE_LOG",
  "result": "success",
  "file_path": "/scratch/gpfs/MSALGANIK/niznik/cap_4L_lora_rank_comparison/design-experiment.jsonl",
  "size_bytes": 2134,
  "num_entries": 14
}
```

#### COMPLETE_DESIGN
```json
{
  "timestamp": "2025-10-22T14:30:08.890Z",
  "action": "COMPLETE_DESIGN",
  "result": "success",
  "experiment_name": "cap_4L_lora_rank_comparison",
  "total_duration_seconds": 8.89,
  "files_created": [
    "experiment_summary.yaml",
    "design-experiment.jsonl"
  ]
}
```

### Error Handling in Logs

When `result: "failure"` or `result: "warning"`, include additional fields:

```json
{
  "timestamp": "2025-10-22T14:30:01.123Z",
  "action": "VERIFY_MODEL",
  "result": "failure",
  "resource_type": "model",
  "resource_name": "Llama-3.2-1B-Instruct",
  "path": "/scratch/gpfs/MSALGANIK/niznik/llms/Meta-Llama-3.2-1B-Instruct",
  "command": "ls -lh /scratch/gpfs/MSALGANIK/niznik/llms/Meta-Llama-3.2-1B-Instruct",
  "error_type": "FileNotFoundError",
  "error_message": "Model directory does not exist",
  "duration_ms": 45
}
```

### Example Complete Log

```jsonl
{"timestamp":"2025-10-22T14:30:00.000Z","action":"START_DESIGN","result":"success","experiment_name":"cap_4L_lora_rank_comparison","experiment_type":"sanity_check","experiment_dir":"/scratch/gpfs/MSALGANIK/niznik/cap_4L_lora_rank_comparison"}
{"timestamp":"2025-10-22T14:30:01.123Z","action":"VERIFY_MODEL","result":"success","resource_type":"model","resource_name":"Llama-3.2-1B-Instruct","path":"/scratch/gpfs/MSALGANIK/niznik/llms/Meta-Llama-3.2-1B-Instruct","command":"ls -lh /scratch/gpfs/MSALGANIK/niznik/llms/Meta-Llama-3.2-1B-Instruct","size_gb":4.0,"duration_ms":45}
{"timestamp":"2025-10-22T14:30:01.456Z","action":"VERIFY_DATASET","result":"success","resource_type":"dataset","path":"/home/sarahep/cruijff_kit/data/green/words_5L_80P_1000.json","command":"ls -lh /home/sarahep/cruijff_kit/data/green/words_5L_80P_1000.json","size_kb":84,"duration_ms":23}
{"timestamp":"2025-10-22T14:30:01.789Z","action":"COUNT_DATASET_SAMPLES","result":"success","dataset":"words_5L_80P_1000.json","command":"jq '.train | length' /home/sarahep/cruijff_kit/data/green/words_5L_80P_1000.json","train_samples":1000,"validation_samples":200,"test_samples":200,"duration_ms":156}
{"timestamp":"2025-10-22T14:30:02.012Z","action":"VERIFY_EVAL_TASK","result":"success","task_name":"capitalization","script_path":"/home/sarahep/cruijff_kit/experiments/capitalization/cap_task.py","command":"ls -lh /home/sarahep/cruijff_kit/experiments/capitalization/cap_task.py","size_kb":12,"duration_ms":34}
{"timestamp":"2025-10-22T14:30:02.234Z","action":"SEARCH_PRIOR_RUNS","result":"success","search_pattern":"find /scratch/gpfs/MSALGANIK/niznik -name 'slurm-*.out' -path '*/ck-out-*'","command":"find /scratch/gpfs/MSALGANIK/niznik -name 'slurm-*.out' -path '*/ck-out-*' | head -10","found_count":3,"paths":["/scratch/gpfs/MSALGANIK/niznik/prior_exp/run1/slurm-123.out"],"duration_ms":890}
{"timestamp":"2025-10-22T14:30:03.567Z","action":"EXTRACT_TRAINING_SPEED","result":"success","prior_run":"/scratch/gpfs/MSALGANIK/niznik/prior_exp/run1/slurm-123.out","command":"grep -E '[0-9.]+it/s' /scratch/.../slurm-123.out | tail -20","iterations_per_sec":2.5,"estimated_seconds_per_epoch":120,"duration_ms":234}
{"timestamp":"2025-10-22T14:30:04.890Z","action":"CALCULATE_TRAINING_TIME","result":"success","basis":"prior_run_average","per_epoch_seconds":120,"epochs":1,"num_runs":2,"total_seconds":240,"total_minutes":4}
{"timestamp":"2025-10-22T14:30:05.123Z","action":"CHECK_DISK_SPACE","result":"success","command":"df -h /scratch/gpfs/MSALGANIK/niznik","available_gb":5120,"used_gb":2048,"total_gb":7168,"duration_ms":67}
{"timestamp":"2025-10-22T14:30:05.456Z","action":"CALCULATE_DISK_USAGE","result":"success","per_checkpoint_gb":2.5,"epochs":1,"num_runs":2,"total_checkpoints":2,"total_gb":5.0}
{"timestamp":"2025-10-22T14:30:06.789Z","action":"GENERATE_RUNS","result":"success","method":"cartesian_product","variables":{"lora_rank":[4,8]},"generated_count":2,"control_runs":1,"total_runs":3}
{"timestamp":"2025-10-22T14:30:07.012Z","action":"GENERATE_EVAL_MATRIX","result":"success","num_runs":3,"num_tasks":1,"total_evaluations":3}
{"timestamp":"2025-10-22T14:30:08.234Z","action":"CREATE_YAML","result":"success","file_path":"/scratch/gpfs/MSALGANIK/niznik/cap_4L_lora_rank_comparison/experiment_summary.yaml","size_bytes":1456}
{"timestamp":"2025-10-22T14:30:08.567Z","action":"CREATE_LOG","result":"success","file_path":"/scratch/gpfs/MSALGANIK/niznik/cap_4L_lora_rank_comparison/design-experiment.jsonl","size_bytes":2134,"num_entries":14}
{"timestamp":"2025-10-22T14:30:08.890Z","action":"COMPLETE_DESIGN","result":"success","experiment_name":"cap_4L_lora_rank_comparison","total_duration_seconds":8.89,"files_created":["experiment_summary.yaml","design-experiment.jsonl"]}
```

---

## File-by-File Changes

### design-experiment Skill

#### 1. `.claude/skills/design-experiment/SKILL.md`
**Changes:**
- Update references from `experiment_summary.md` to `experiment_summary.yaml`
- Update log file references from `.log` to `.jsonl`
- Update workflow description to mention YAML generation

**Estimated lines changed:** ~10-15

---

#### 2. `.claude/skills/design-experiment/templates/experiment_summary.yaml` (NEW)
**Purpose:** Replace `templates/experiment_summary.md`

**Content:** Complete YAML template with:
- Schema documentation via comments
- Example values for all fields
- REQUIRED/OPTIONAL annotations

**Estimated lines:** ~150-200

---

#### 3. `.claude/skills/design-experiment/templates/experiment_summary.md` (DELETE)
**Action:** Remove file after confirming YAML template is complete

---

#### 4. `.claude/skills/design-experiment/logging.md`
**Changes:**
- Complete rewrite to document `.jsonl` format
- Define all action types with schemas
- Provide examples for each action type
- Document error handling patterns
- Remove human-readable log format references

**Estimated lines changed:** ~80-100 (most of file)

---

#### 5. `.claude/skills/design-experiment/experiment_generation.md`
**Changes:**
- Update file creation instructions for YAML instead of MD
- Update log file creation for `.jsonl` instead of `.log`
- Remove instructions about Markdown formatting
- Add YAML generation guidance (use PyYAML-style formatting)
- Update next steps conversation pattern

**Estimated lines changed:** ~40-50

---

#### 6. `.claude/skills/design-experiment/param_selection.md`
**Changes:**
- Update references from MD to YAML throughout
- Remove Quick Reference generation steps
- Remove Compute Estimates generation steps
- Update log file references to `.jsonl`
- Clarify that verification happens during generation

**Estimated lines changed:** ~20-30

---

#### 7. `.claude/skills/design-experiment/validation.md`
**Changes:**
- Update validation checklist for YAML structure
- Remove validation steps for removed sections (Quick Reference, Compute Estimates)
- Add YAML structure validation (proper nesting, required fields)
- Update system prompt consistency checks

**Estimated lines changed:** ~30-40

---

### scaffold-experiment Skill

#### 8. `.claude/skills/scaffold-experiment/SKILL.md`
**Changes:**
- Update all references from `experiment_summary.md` to `experiment_summary.yaml`
- Update verification step to check for YAML file
- Update tool specification parsing section for YAML structure
- Update example outputs in documentation

**Estimated lines changed:** ~15-20

---

#### 9. `.claude/skills/scaffold-experiment/optimizers/torchtune/parsing.md`
**Changes:**
- Complete rewrite of parsing logic for YAML structure
- Update field access paths (YAML keys instead of Markdown sections)
- Simplify parsing instructions (no more table parsing)
- Update error handling for missing YAML keys
- Add YAML parsing examples

**Estimated lines changed:** ~50-60 (most of file)

**New parsing patterns:**
```python
# Old: Parse "All Runs" Markdown table
# New: Parse runs list from YAML
runs = yaml_data['runs']
for run in runs:
    if run['type'] == 'fine-tuned':
        name = run['name']
        params = run['parameters']
        lora_rank = params.get('lora_rank')
```

---

#### 10. `.claude/skills/scaffold-experiment/evaluators/inspect/parsing.md`
**Changes:**
- Complete rewrite of parsing logic for YAML structure
- Update field access paths for YAML
- Simplify evaluation matrix parsing
- Update error handling for missing YAML keys
- Add YAML parsing examples

**Estimated lines changed:** ~40-50 (most of file)

**New parsing patterns:**
```python
# Old: Parse "Evaluation Plan" Markdown section
# New: Parse evaluation.matrix from YAML
eval_matrix = yaml_data['evaluation']['matrix']
for entry in eval_matrix:
    run_name = entry['run']
    tasks = entry['tasks']
    epochs = entry['epochs']  # Can be None for control runs
```

---

### run-experiment Skill

#### 11. `.claude/skills/run-experiment/optimizers/torchtune/parsing.md`
**Changes:**
- Update references from `experiment_summary.md` to `experiment_summary.yaml`
- Update parsing examples for YAML structure
- Simplify run identification logic

**Estimated lines changed:** ~20-30

---

#### 12. `.claude/skills/run-experiment/evaluators/inspect/parsing.md`
**Changes:**
- Update references from `experiment_summary.md` to `experiment_summary.yaml`
- Update parsing examples for YAML structure
- Simplify evaluation matrix parsing

**Estimated lines changed:** ~20-30

---

#### 13. `.claude/skills/run-experiment/SKILL.md`
**Changes:**
- Update references from `experiment_summary.md` to `experiment_summary.yaml`

**Estimated lines changed:** ~5-10

---

### create-inspect-task Skill

#### 14. `.claude/skills/create-inspect-task/SKILL.md`
**Changes:**
- Update experiment-guided mode to parse `experiment_summary.yaml`
- Update field access examples for YAML structure

**Estimated lines changed:** ~10-15

---

### Documentation

#### 15. `CLAUDE.md`
**Changes:**
- Update workflow references from MD to YAML
- Update skill descriptions
- Update example file paths

**Estimated lines changed:** ~5-10

---

#### 16. `ARCHITECTURE.md`
**Changes:**
- Update experiment design section for YAML format
- Update file structure examples
- Document YAML schema (or reference this refactoring doc)

**Estimated lines changed:** ~20-30

---

#### 17. `.claude/workflow_test.yaml`
**Changes:**
- Update expected outputs from `.md` to `.yaml`
- Update validation steps to check YAML structure

**Estimated lines changed:** ~5-10

---

#### 18. `.claude/workflow_test_base.yaml`
**Changes:**
- Update expected outputs from `.md` to `.yaml`
- Update validation steps to check YAML structure

**Estimated lines changed:** ~5-10

---

## Implementation Order

The refactoring should follow this order to maintain working functionality:

### Phase 1: Template and Documentation (No Breaking Changes)
**Goal:** Create new templates and update design-experiment skill documentation

1. **Create YAML template** - `.claude/skills/design-experiment/templates/experiment_summary.yaml`
2. **Update logging documentation** - `.claude/skills/design-experiment/logging.md`
3. **Update generation instructions** - `.claude/skills/design-experiment/experiment_generation.md`
4. **Update parameter selection** - `.claude/skills/design-experiment/param_selection.md`
5. **Update validation checklist** - `.claude/skills/design-experiment/validation.md`
6. **Update skill entry point** - `.claude/skills/design-experiment/SKILL.md`

**Testing:** Run `design-experiment` skill and verify:
- ✓ Creates `experiment_summary.yaml` (not `.md`)
- ✓ Creates `design-experiment.jsonl` (not `.log`)
- ✓ YAML follows schema specification
- ✓ Log entries are valid JSON Lines
- ✓ All required fields present

**Status after Phase 1:** design-experiment generates YAML, but downstream skills can't parse it yet

---

### Phase 2: Scaffold Parsing (Breaking Change Begins)
**Goal:** Update scaffold-experiment to parse YAML instead of MD

6. **Update scaffold-torchtune parsing** - `.claude/skills/scaffold-experiment/optimizers/torchtune/parsing.md`
7. **Update scaffold-inspect parsing** - `.claude/skills/scaffold-experiment/evaluators/inspect/parsing.md`
8. **Update scaffold-experiment orchestrator** - `.claude/skills/scaffold-experiment/SKILL.md`

**Testing:** Run complete workflow (`design-experiment` → `scaffold-experiment`):
- ✓ scaffold-torchtune correctly parses YAML
- ✓ Creates correct directory structure
- ✓ Generates correct `setup_finetune.yaml` files
- ✓ scaffold-inspect correctly parses YAML
- ✓ Generates correct `inspect.slurm` files
- ✓ All parameters match expected values

**Status after Phase 2:** design + scaffold workflow works end-to-end with YAML

---

### Phase 3: Run Parsing (Complete Workflow)
**Goal:** Update run-experiment to parse YAML

9. **Update run-torchtune parsing** - `.claude/skills/run-experiment/optimizers/torchtune/parsing.md`
10. **Update run-inspect parsing** - `.claude/skills/run-experiment/evaluators/inspect/parsing.md`
11. **Update run-experiment orchestrator** - `.claude/skills/run-experiment/SKILL.md`

**Testing:** Run complete workflow (`design` → `scaffold` → `run`):
- ✓ run-torchtune correctly identifies runs from YAML
- ✓ Submits correct jobs
- ✓ run-inspect correctly identifies evaluations from YAML
- ✓ Submits correct evaluation jobs

**Status after Phase 3:** Full workflow works with YAML

---

### Phase 4: Related Skills and Documentation
**Goal:** Update remaining skills and project documentation

12. **Update create-inspect-task** - `.claude/skills/create-inspect-task/SKILL.md`
13. **Update CLAUDE.md** - Root project documentation
14. **Update ARCHITECTURE.md** - Architecture documentation
15. **Update workflow tests** - `.claude/workflow_test.yaml`, `.claude/workflow_test_base.yaml`

**Testing:**
- ✓ create-inspect-task works in experiment-guided mode
- ✓ Workflow tests pass with new YAML format
- ✓ Documentation examples are accurate

**Status after Phase 4:** All skills and documentation updated

---

### Phase 5: Cleanup
**Goal:** Remove obsolete files

16. **Delete MD template** - `.claude/skills/design-experiment/templates/experiment_summary.md`

**Testing:**
- ✓ No skills reference deleted file
- ✓ All tests still pass

**Status after Phase 5:** Refactoring complete

---

## Testing Strategy

### Unit Testing Approach

For each phase, test individual components:

1. **YAML Generation Testing (Phase 1)**
   - Run design-experiment on simple experiment (2 runs, 1 eval task)
   - Verify YAML is valid (can be parsed by PyYAML)
   - Verify all required fields present
   - Verify structure matches schema
   - Check `.jsonl` log is valid (each line parses as JSON)
   - Verify log contains expected action types

2. **Scaffold Parsing Testing (Phase 2)**
   - Create minimal test YAML file
   - Run scaffold-torchtune and verify correct parsing
   - Run scaffold-inspect and verify correct parsing
   - Check generated configs match expected values
   - Verify error handling for malformed YAML

3. **Run Parsing Testing (Phase 3)**
   - Use scaffolded experiment from Phase 2
   - Run run-torchtune (may use dry-run mode)
   - Run run-inspect (may use dry-run mode)
   - Verify correct job identification and submission

### Integration Testing Approach

Use workflow test specifications (`.claude/workflow_test*.yaml`):

1. **Run complete workflow test**
   ```bash
   # User says: "test the workflow"
   # Claude asks which variant, user selects "LoRA Comparison"
   # Claude runs: design-experiment → scaffold-experiment → run-experiment
   ```

2. **Verify outputs at each stage**
   - After design: Check YAML structure, log format
   - After scaffold: Check generated configs
   - After run: Check job submissions (may cancel immediately)

3. **Compare with expected behavior**
   - Same runs generated as before
   - Same configs generated as before
   - Same evaluations scheduled as before

### Regression Testing

To ensure no functionality is lost:

1. **Create experiments before refactor** (if not already done)
   - Save MD version of experiment_summary
   - Save all generated configs

2. **After Phase 2, compare outputs**
   - Run same experiment with YAML
   - Compare generated configs (should be identical)
   - Verify same directory structure created

3. **Monitor for issues**
   - Check that no fields are missing
   - Verify downstream skills get all needed info

---

## Migration Notes

### No Backward Compatibility Required

Per user specification:
- ✗ Do NOT support reading old `.md` files
- ✗ Do NOT provide conversion tools
- ✓ Clean break to new format

### Handling Existing Experiments

Experiments designed with old format (`.md`):
- Can still be run manually (configs already generated)
- Cannot be re-scaffolded without redesigning
- If modification needed, user should redesign from scratch with new format

### Communication

When refactor is complete, announce:
1. ✅ design-experiment now generates YAML + JSONL
2. ✅ All downstream skills updated to parse YAML
3. ✅ Old MD format no longer supported
4. ✅ Run workflow tests to validate installation

---

## Open Questions

1. **YAML library:** Should skills use Python's `yaml` module, or handle YAML parsing through Claude's understanding?
   - **Recommendation:** Skills should instruct to use Python `yaml` module for robustness

2. **Validation:** Should we add YAML schema validation (e.g., using jsonschema on loaded YAML)?
   - **Recommendation:** Optional for future enhancement; not required for initial refactor

3. **Partial runs:** If a run list is very long, should we support truncation or pagination in YAML?
   - **Recommendation:** Not needed initially; YAML handles large lists fine

4. **Comments in YAML:** Should generated YAML include explanatory comments?
   - **Recommendation:** Yes, minimal comments for clarity (e.g., "# Control run - no training")

---

## Success Criteria

Refactoring is complete when:

- ✅ design-experiment generates valid `experiment_summary.yaml`
- ✅ design-experiment generates valid `design-experiment.jsonl`
- ✅ scaffold-torchtune parses YAML correctly
- ✅ scaffold-inspect parses YAML correctly
- ✅ run-torchtune parses YAML correctly
- ✅ run-inspect parses YAML correctly
- ✅ create-inspect-task experiment-guided mode works with YAML
- ✅ Workflow tests pass with new format
- ✅ All documentation updated
- ✅ Old MD template removed

---

## Estimated Effort

**Total lines changed:** ~500-700 lines across ~18 files

**Breakdown by phase:**
- Phase 1 (Template + design-experiment): ~200-250 lines
- Phase 2 (Scaffold parsing): ~150-200 lines
- Phase 3 (Run parsing): ~80-100 lines
- Phase 4 (Related skills + docs): ~50-80 lines
- Phase 5 (Cleanup): ~10 lines

**Implementation time estimate:** 6-10 hours (with testing)

---

## References

- **Original motivation:** https://github.com/msalganik/torchtune_config_writer/blob/master/REFACTORING_PLAN.md
- **Current design-experiment:** `.claude/skills/design-experiment/`
- **Current scaffold-experiment:** `.claude/skills/scaffold-experiment/`
- **Workflow tests:** `.claude/workflow_test.yaml`, `.claude/workflow_test_base.yaml`
