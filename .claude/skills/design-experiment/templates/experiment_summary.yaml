# experiment_summary.yaml Template
#
# This file defines the structure for experiment design in cruijff_kit.
# All fields marked REQUIRED must be present. OPTIONAL fields can be omitted.
#
# =============================================================================
# EXPERIMENT METADATA
# =============================================================================

experiment:
  name: string                     # REQUIRED: Experiment identifier (e.g., "cap_4L_lora_rank_comparison")
  question: string                 # REQUIRED: Scientific question being addressed
  date: string                     # REQUIRED: YYYY-MM-DD format
  hypothesis: string               # OPTIONAL: Expected outcome
  purpose: string                  # OPTIONAL: Why this experiment matters
  directory: string                # REQUIRED: Full path to experiment directory

# =============================================================================
# TOOL CONFIGURATION
# =============================================================================

tools:
  preparation: string              # REQUIRED: "torchtune" (for scaffold routing)
  evaluation: string               # REQUIRED: "inspect-ai" (for scaffold routing)

# =============================================================================
# EXPERIMENTAL DESIGN
# =============================================================================

variables:
  # OPTIONAL: Parameters that vary across runs
  # Key = parameter name, Value = list of values to sweep
  # Example:
  # lora_rank: [4, 8, 16]
  # learning_rate: [1e-5, 5e-5]
  # batch_size: [2, 4, 8]

controls:
  base_recipe: string              # Torchtune recipe name (e.g., "lora_finetune_single_device")
                                   # TORCHTUNE RECIPES NOT IMPLEMENTED YET
  # OPTIONAL: Experimental hyperparameters for setup_finetune.py
  epochs: int                      # Number of training epochs
  batch_size: int                  # Batch size (if not varied)
  system_prompt: string            # Training system prompt ("" for blank)
  validation_during_training: bool # Whether to run validation during training
  # Add any other constant hyperparameters as needed

# =============================================================================
# RESOURCES
# =============================================================================

models:
  base:
    - name: string                 # REQUIRED: Model identifier (e.g., "Llama-3.2-1B-Instruct")
      path: string                 # REQUIRED: Full path to model directory
      size_gb: float               # REQUIRED: Model size for disk estimates

data:
  training:
    path: string                   # REQUIRED: Full path to training dataset
    label: string                  # REQUIRED: Filename without extension
    format: string                 # REQUIRED: "json" or "parquet"
    size_kb: int                   # REQUIRED: Dataset size in KB
    splits:                        # REQUIRED: Sample counts per split
      train: int
      validation: int
      test: int

output:
  base_directory: string           # REQUIRED: Full path to this experiment's output directory
                                   # Construction: read "Output base directory" from claude.local.md, append experiment name
                                   # Format: {output_base_from_claude_local}/{experiment_name}
                                   # Example: "/scratch/gpfs/MSALGANIK/niznik/ck-outputs/workflow_test_2025-11-28"
  checkpoint_pattern: string       # REQUIRED: Pattern for checkpoint paths relative to base_directory
                                   # Standard value: "ck-out-{run_name}/epoch_{N}"
                                   # Full checkpoint path: {base_directory}/ck-out-{run_name}/epoch_{N}
  wandb_project: string            # REQUIRED: Weights & Biases project name

# =============================================================================
# RUNS DEFINITION
# =============================================================================

runs:
  # REQUIRED: List of all runs (fine-tuned + control)
  # Generated from cartesian product of variables + explicit controls

  # Example fine-tuned run:
  - name: string                   # REQUIRED: Run identifier (used for directory name)
    type: string                   # REQUIRED: "fine-tuned" or "control"
    model: string                  # REQUIRED: Model name (matches models.base[].name)
    parameters:                    # REQUIRED: Parameter values for this run
      lora_rank: int               # Include all varied parameters
      learning_rate: float
      # Empty dict {} for control runs

  # Example control run:
  - name: string                   # e.g., "Llama-3.2-1B-Instruct_base"
    type: "control"
    model: string
    parameters: {}                 # Empty for control runs

# =============================================================================
# EVALUATION CONFIGURATION
# =============================================================================

evaluation:
  system_prompt: string            # REQUIRED: Must match training system prompt
  temperature: float               # REQUIRED: Evaluation temperature (typically 0.0)
  scorer: string                   # REQUIRED: Inspect-ai scorer type (e.g., "match")

  tasks:
    # REQUIRED: List of evaluation tasks
    - name: string                 # REQUIRED: Task identifier (e.g., "capitalization")
      script: string               # REQUIRED: Full path to inspect-ai task script
      dataset: string              # OPTIONAL: Path to eval dataset (if different from training)
      description: string          # REQUIRED: Human-readable task description

  matrix:
    # REQUIRED: Which runs evaluate on which tasks at which epochs
    - run: string                  # REQUIRED: Run name (matches runs[].name)
      tasks: [string]              # REQUIRED: List of task names
      epochs: [int]                # REQUIRED: List of epoch numbers (0-indexed)
                                   # Use null for control runs (no epochs)
