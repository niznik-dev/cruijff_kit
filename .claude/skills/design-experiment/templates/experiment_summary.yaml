# experiment_summary.yaml Template
#
# This file defines the structure for experiment design in cruijff_kit.
# All fields marked REQUIRED must be present. OPTIONAL fields can be omitted.
#
# =============================================================================
# EXPERIMENT METADATA
# =============================================================================

experiment:
  name: string                     # REQUIRED: Experiment identifier (e.g., "cap_4L_lora_rank_comparison")
  question: string                 # REQUIRED: Scientific question being addressed
  date: string                     # REQUIRED: YYYY-MM-DD format
  hypothesis: string               # OPTIONAL: Expected outcome
  purpose: string                  # OPTIONAL: Why this experiment matters
  directory: string                # REQUIRED: Full path to experiment directory

# =============================================================================
# TOOL CONFIGURATION
# =============================================================================

tools:
  preparation: string              # REQUIRED: "torchtune" (for scaffold routing)
  evaluation: string               # REQUIRED: "inspect-ai" (for scaffold routing)

# =============================================================================
# EXPERIMENTAL DESIGN
# =============================================================================

variables:
  # OPTIONAL: Parameters that vary across runs
  # Key = parameter name, Value = list of values to sweep
  # Key names should match torchtune recipes (for instance, the learning rate is lr)
  # Example:
  # lora_rank: [4, 8, 16]
  # lr: [1e-5, 5e-5]
  # batch_size: [2, 4, 8]

controls:
  system_prompt: string            # Training system prompt ("" for blank)
  prompt: string                   # Prompt template with {input} placeholder (e.g., "Capitalize: {input}\n")
  # Common hyperparameters (see param_selection.md for full list)
  epochs: int                      # Number of training epochs
  batch_size: int                  # Batch size (if not varied)
  validation_during_training: bool # Whether to run validation during training
  # Additional parameters can be added as needed (lora_rank, lr, weight_decay, etc.)

# =============================================================================
# RESOURCES
# =============================================================================

models:
  base:
    - name: string                 # REQUIRED: Model identifier (e.g., "Llama-3.2-1B-Instruct")
      path: string                 # REQUIRED: Full path to model directory
      size_gb: float               # REQUIRED: Model size for disk estimates
      base_recipe: string          # OPTIONAL: Torchtune recipe for default hyperparameters
                                   # e.g., "llama3_2/1B_lora_single_device"
                                   # When specified, recipe defaults are used for hyperparameters not set
                                   # Use `tune ls` to see available recipes


data:
  training:
    path: string                   # REQUIRED: Full path to training dataset
    label: string                  # REQUIRED: Filename without extension
    format: string                 # REQUIRED: "json" or "parquet"
    size_kb: int                   # REQUIRED: Dataset size in KB
    splits:                        # REQUIRED: Sample counts per split
      train: int
      validation: int
      test: int

output:
  base_directory: string           # REQUIRED: Full path to this experiment's output directory
                                   # Construction: read "Scratch directory" from claude.local.md, append "ck-outputs/" and experiment name
                                   # Format: {scratch_dir}/ck-outputs/{experiment_name}
                                   # Example: "{scratch_dir}/ck-outputs/my_experiment_2025-10-22"
  checkpoint_pattern: string       # REQUIRED: Pattern for checkpoint paths relative to base_directory
                                   # Standard value: "ck-out-{run_name}/epoch_{N}"
                                   # Full checkpoint path: {base_directory}/ck-out-{run_name}/epoch_{N}
  wandb_project: string            # REQUIRED: Weights & Biases project name

# =============================================================================
# RUNS DEFINITION
# =============================================================================

runs:
  # REQUIRED: List of all runs (fine-tuned + control)
  # Generated from cartesian product of variables + explicit controls

  # Example fine-tuned run:
  - name: string                   # REQUIRED: Run identifier (used for directory name)
    type: string                   # REQUIRED: "fine-tuned" or "control"
    model: string                  # REQUIRED: Model name (matches models.base[].name)
    parameters:                    # REQUIRED: Parameter values for this run
      lora_rank: int               # Include all varied parameters
      lr: float
      # Empty dict {} for control runs

  # Example control run:
  - name: string                   # e.g., "Llama-3.2-1B-Instruct_base"
    type: "control"
    model: string
    parameters: {}                 # Empty for control runs

# =============================================================================
# EVALUATION CONFIGURATION
# =============================================================================

evaluation:
  system_prompt: string            # REQUIRED: Must match training system prompt
  temperature: float               # REQUIRED: Evaluation temperature (typically 0.0)
  scorer:                            # REQUIRED: Inspect-ai scorer(s) - list of scorers with optional params
    - name: string                   # REQUIRED: Scorer name (e.g., "match", "includes", "risk_scorer")
      params:                        # OPTIONAL: Parameters passed to the scorer
        key: value                   # e.g., option_tokens: ["0", "1"] for risk_scorer

  tasks:
    # REQUIRED: List of evaluation tasks
    - name: string                 # REQUIRED: Task identifier (e.g., "capitalization")
      script: string               # REQUIRED: Full path to inspect-ai task script
      dataset: string              # OPTIONAL: Path to eval dataset (if different from training)
      description: string          # REQUIRED: Human-readable task description

  matrix:
    # REQUIRED: Which runs evaluate on which tasks at which epochs
    - run: string                  # REQUIRED: Run name (matches runs[].name)
      vis_label: string            # OPTIONAL: Label for visualization (defaults to run name)
                                   # Used to set dynamic task name suffix (e.g., "rank4" -> "capitalization_rank4")
      tasks: [string]              # REQUIRED: List of task names
      epochs: [int]                # REQUIRED: List of epoch numbers (0-indexed)
                                   # Use null for control runs (no epochs)

  baseline:
    # OPTIONAL: Comparison point when no control run exists in experiment
    # Use ONE of the following approaches:

    # Approach 1: Known accuracy value (e.g., random chance)
    accuracy: float                # Known baseline accuracy (e.g., 0.5 for binary classification)
    source: string                 # Where this value comes from (e.g., "random chance (binary)")

    # Approach 2: Explicit run as baseline (alternative to type: "control")
    # run: string                  # Run name to use as baseline (matches runs[].name)
