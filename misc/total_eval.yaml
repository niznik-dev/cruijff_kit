# -------------------------------------------------------------
# Description: Configuration File for total_eval.py
#   Used to specify: 
#     - Directories for model, adapters, and data
#     - Target tokens to obtain probabilities for
#     - Tokenization, batch, and token generation parameters
# -------------------------------------------------------------


# ----------- Static Directories:
BASE_DIR: '/home/drigobon/scratch/'
  # Directory wherein everything else is relative


# ----------- Input / Output Data
EVAL_DATASET_PATH: '/zyg-in/ptwindat_eval.json' # TODO -- come up with something for testing this
  # Within "{BASE_DIR}"
NUM_OBS: null
INPUT_COLNAME: 'input'
OUTPUT_COLNAME: 'output'
ID_COLNAME: null

OUTPUT_PATH: '/zyg-out/' # TODO -- come up with somethign for testing this
  # Within ...?
  

# ----------- Model Params
MODEL_PATH: "/torchtune-models/Llama-3.2-1B-Instruct/"
  # Within "{BASE_DIR}"
ADAPTER_PATH: "/zyg-out/100k-20epoch/"
  # Within "{BASE_DIR}"
ADAPTER_NAMES:
  - null
  - epoch_0
  - epoch_1
  - epoch_2
  - epoch_3
  - epoch_4
  - epoch_5
  - epoch_6
  - epoch_7
  - epoch_8
  - epoch_9
  # Within "{BASE_DIR}/{ADAPTER_PATH}" (except for 'null', which evaluates base model)

# ----------- Task & Tokenization Params
TARGET_TOKENS: ['0', '1', '2']

PREPROMPT: "The following contains features about two individuals, serialized into text. The features and their units, along with the individuals, are anonymized. Your task is to predict whether the two individuals are twins. Return a '1' if you believe they are, and a '0' otherwise. Do not return more than one number, and do not provide any explanation or justification.'"

# ----------- Execution Params
BATCH_SIZE: 16
USE_CHAT_TEMPLATE: true
ONLY_NEW_TOKENS: true
NUM_GPUS: 1
MAX_LENGTH: null
MAX_NEW_TOKENS: 1


